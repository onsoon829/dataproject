{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk+ivpZl5FHirwNTmFpvIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onsoon829/dataproject/blob/master/002_%EC%9D%8C%EC%84%B1%EB%B9%84%EC%84%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd  '/content/drive/MyDrive/ai_chat_python'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbByh7ISOuXk",
        "outputId": "0de764b6-7f11-42a1-9aaf-fdf963789c3e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/ai_chat_python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 텍스트를 음성 파일로 변환하는 gTTS 사용\n",
        "\n",
        "- 텍스트를 음성파일로 변환하는 TTS(Text-To-Speech)\n",
        "- TTS 기능을 구현하기 위해 gTTS라는 무료 TTS 패키지를 사용\n",
        "  - gTTS 공식 홈페이지 https://pypi.org/project/gTTS/\n",
        "  - 구글 클라우드의 유료 TTS 서비스 https://cloud.google.com/text-to-speech?hl=ko"
      ],
      "metadata": {
        "id": "mAkWv1uiOdcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usZNZX2LOXeS",
        "outputId": "458ed667-420c-40c8-b069-674591d47079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.org/project/gTTS/\n",
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "tts = gTTS(text=\"안녕하세요 음성비서 프로그램 실습중입니다.\",lang=\"ko\")\n"
      ],
      "metadata": {
        "id": "GKCZ7MGoO4fc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# openai 라이브러리 설치\n",
        "!pip install openai==0.28.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6IdJVnYQwD9",
        "outputId": "b918a47c-847b-4ddd-ab02-b3fd59cd4752"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 음성 파일을  텍스트로 변환하는 Whisper API 사용\n",
        "\n",
        "- Whisper란  ChatGPT로 유명한 OpenAI에서 공개한 인공지능 모델로, 음성을 텍스트로 변환해 주는 Speech to Text(STT) 기술이다.\n",
        "- 약 68만 시간 분량의 방대한 데이터를 학습시켜 영어, 한국어를 포함한 다양한 언어를 인식할 수 있으며, 번역 및 언어 식별 기능이 있다.\n",
        "- Whisper 모델은 오픈소스로 공개돼 있으며 구체적인 모델의 구조는 공식 홈페이지에서 확인할 수 있다.\n",
        " -  https://openai.com/research/whisper\n",
        "- Whisper 가격\n",
        " - https://openai.com/pricing"
      ],
      "metadata": {
        "id": "sG0OwK2VPp4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 코드로 형식 지정됨\n",
        "import openai\n",
        "\n",
        "openai.api_key='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'  # openAPI API key\n",
        "# 녹음파일 열기\n",
        "audio_file = open(\"output.mp3\", \"rb\")\n",
        "# whisper 모델에 음원파일 전달하기\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "print(dir(transcript))\n",
        "# 결과 보기\n",
        "print(transcript[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "EDn2GzHaQAts",
        "outputId": "c6c5de66-0ab3-4d47-ce4d-fbac0515f392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6dcd5a84a472>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'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'\u001b[0m  \u001b[0;31m# openAPI API key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 녹음파일 열기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.mp3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# whisper 모델에 음원파일 전달하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"whisper-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output.mp3'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 프로그램 UI를 생성하는 스트림릿 사용\n",
        "\n",
        "- 스트림릿(Streamlit)은 데이터 과학, 머신러닝, 분석 프로젝트를 위한 웹 어플리케이션을 만드는 과정을 간소화하고, 신속하게 웹 애플리케이션을 만들 수 있게 설계된 오픈소스이다.\n",
        "- 사용자가 앱을 사용할 때 실제로 보는 타이틀, 버튼과 같은 UI를 손쉽게 만들 수 있으며, 직관적이고 사용자 친화적인 프레임워크이다.\n",
        "- 스트림릿을 활용하면 웹 개발에 대한 광범위한 지식이 없더라도 간단한 파이썬 스크립트 작성으로 애플리케이션을 빠르게 구축할 수 있다.\n",
        "- 스트림릿 주요 기능과 장점\n",
        "  - 간단한 사용법 : 스트림릿의 문법은 매우 간단하여 파이썬을 기초 수준으로 이해하는 사용자라면 손쉽게 사용할 수 있다.\n",
        "  - 빠른 개발 속도 : 웹 애플리케이션을 빠르게 빌드할 수 있으며, 반복적인 프로토타이핑과 배포 속도를 높일 수 있다.\n",
        "  - 뛰어난 인터렉티브 기능 : 스트림릿에 내장된 위젯을 사용하면 최소한의 코딩으로 사용자와 원활한 상호 작용이 가능하다.\n",
        "  - 시각적 사용자 정의 기능 : 스트림릿은 Matplotlib, Plotly, Altair와 같이 널리 사용되는 데이터 시각화 라이브러리를 쉽게 통합할 수 있어 다양한 시각적 사용자 정의가 가능하다.\n",
        "  - 실시간 업데이트 : 코드를 수정하면 스트림릿 애플리케이션이 자동 업데이트되어 효율적인 개발 환경을 제공한다.\n",
        "  - 간편한 공유 기능 : 간소화된 배포 프로세스를 제공하여 다른 사용자에게 애플리케이션을 쉽게 공유할 수 있다.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "k508qea3ULtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|기능|Streamlit|Django|Flask|\n",
        "|---|---|---|---|\n",
        "|데이터 과학 및 머신 러닝에 특화| ㅇ | X | X |\n",
        "|사용의 용이성|높음(최소한의 코딩 필요) | 중간(많은 학습 필요)|중간(웹 개발 이해 필요)|\n",
        "|웹 개발 지식 필요여부| X | ㅇ | ㅇ |\n",
        "\n",
        "\n",
        "- 스트림릿 기본 함수\n",
        "  - st.title( ) : 앱에 제목을 생성한다.\n",
        "  - st.header( ) : 앱에 헤더를 생성한다.\n",
        "  - st.subheader( ) : 앱에 서브헤더를 생성한다.\n",
        "  - st.text( ) : 앱에 일반 텍스트를 생성한다.\n",
        "  - st.write( ) : 앱에 텍스트나 데이터를 생성한다. 이 함수를 다용도로 사용할 수 있으며 텍스트, 데이터 프레임 또는 플롯을 표시할 수 있다."
      ],
      "metadata": {
        "id": "uj5CZ-rFURPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnWsvU6KVG-i",
        "outputId": "ec23eebd-5b12-4034-a0f2-3e889dff1654"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.29.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.11.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_example.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"나의 첫 번째 Streamlit 앱\")\n",
        "\n",
        "st.header(\"Streamlit에 오신 것을 환영합니다\")\n",
        "st.subheader(\"웹 앱을 만들기 위한 강력하고 사용하기 쉬운 라이브러리\")\n",
        "\n",
        "st.text(\"이것을 일반 텍스트입니다.\")\n",
        "\n",
        "st.write(\"write() 함수를 사용하여 텍스트, 데이터 또는 플롯을 표시할 수도 있습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctCItGaQVdr0",
        "outputId": "5cd45e10-55dd-4258-9b99-0d377dc14243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_example.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000 # port: 논리적인 접속장소\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/streamlit_example.py ==server.port=5000\n",
        "!streamlit run streamlit_example.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrIlp59vWdnk",
        "outputId": "f09ad187-cba1-4b85-ec66-a0e519115515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://4df7-34-150-155-142.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.155.142:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 스트림릿으로 음성 비서 프로그램의 UI 만들기\n",
        "\n",
        "- 기본 설명 영역 : 제목과 기본 정보를 설명하는 영역이다.\n",
        "- 옵션 선택 영역 : OpenAI API 키를 입력받고, GPT 모델을 선택하기 위한 라디오 버튼과 초기화 버튼이 있는 영역이다.\n",
        "- 기능 구현 영역 : 음성을 녹음하고, 녹음한 음성을 재생하는 기능과 이를 채팅창 화면으로 보여주는 영역이다."
      ],
      "metadata": {
        "id": "tSD6hNL2Z2rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st"
      ],
      "metadata": {
        "id": "xShb04WO38AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "   page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        " )\n",
        "\n",
        " # 제목\n",
        " st.header('음성 비서 프로그램')\n",
        "\n",
        " # 구분선\n",
        " st.markdown('---------')\n",
        "\n",
        " # 기본 설명\n",
        " with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "   st.write(\n",
        "    ```\n",
        "    - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "    - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "    ````\n",
        "\n",
        "   )\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILcs-yWoZ9vi",
        "outputId": "40aa7e23-b214-40d6-8789-688739dd2582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSaa4_TKb-G7",
        "outputId": "d6b436fd-205c-46b9-9078-7b1cd5e46f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://2af8-34-150-155-142.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.155.142:5000\u001b[0m\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-12-28T00:46:43+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-5cf46071-7609-44e5-9b3f-8d2815fa4662 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2023-12-28T00:46:43+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-9b4596ea-1402-4d28-9a2d-f17a9c1c1e2c acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "import openai\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "    page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        "  )\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "      '''\n",
        "      - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "      - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "      '''\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  ################################\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='API-Key 입력', placeholder='Enter Your API KEY', value='', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      pass\n",
        "##########################\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQGB3e8ucrZ6",
        "outputId": "ad6f7e0d-90bd-4902-cc1d-c08cfa1f418f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NftLF2jLeAyq",
        "outputId": "57573646-5b4e-4113-f2af-a89614011376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://af0f-35-230-189-14.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.189.14:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "Exception ignored in: <module 'threading' from '/usr/lib/python3.10/threading.py'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1518, in _shutdown\n",
            "    def _shutdown():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/bootstrap.py\", line 69, in signal_handler\n",
            "    server.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/web/server/server.py\", line 397, in stop\n",
            "    self._runtime.stop()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/runtime.py\", line 308, in stop\n",
            "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 798, in call_soon_threadsafe\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 515, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기능 영역 구현하기"
      ],
      "metadata": {
        "id": "38UgpXSk9T7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "# openai 패키지 추가\n",
        "import openai\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "    page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        "  )\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "      '''\n",
        "      - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "      - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "      '''\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  ################################\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='API-Key 입력', placeholder='Enter Your API KEY', value='', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "      pass\n",
        "##########################\n",
        "# 기능 구현 공간(기능 구현 위하여)\n",
        "######################\n",
        "  col1, col2 = st.columns(2)\n",
        "  with col1:\n",
        "    #왼쪽 영역 생성\n",
        "    st.subheader('질문하기')\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 생성\n",
        "    st.subheader('질문/답변')\n",
        "###############################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_VJYnwe9RSj",
        "outputId": "817f78ca-4a2d-4d7c-efad-4d3ab17fd256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t0QXuUv_CPC",
        "outputId": "af0cbebb-c24a-41ad-8f48-48481d3c9793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://4665-35-230-189-14.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.189.14:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 스트림릿의 상태를 저장하기 위한 session_state 함수\n",
        "\n",
        "- 스트림릿 프로그램은 사용자가 버튼을 누르거나 텍스트를 입력할 때마다 코드가 처음부터 끝까지 재실행되는데, 이 과정에서 내부의 모든 변수가 초기화 된다.\n",
        "- 예를 들어, ChatGPT에게 처음 질문을 한 후 이어서 두 번째 질문을 하기 위해 녹음 버튼을 한 번 더 클릭하면 프로그램이 처음부터 다시 실행된다.\n",
        "- 이로 인해 변수들이 모두 초기화되고, 첫번째 질문의 기록이 사라지는 문제가 발생한다. 이러한 문제를 해결하는 방법이 session_state이다.\n",
        "- st.session_state는 스트림릿에서 사용하는 저장 공간으로, session_state을 이용하면 프로그램을 재실행하더라도 정보가 초기화되지 않고 계속 유지된다.\n",
        "- session_state는 파이썬의 딕셔너리 형태로 여러 개의 정보를 저장할 수 있다."
      ],
      "metadata": {
        "id": "l9KOFaRR_Nna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "상태를 저장하기 위한 session_state 추가  \n",
        "\n",
        "- st.session_state['chat'] : 사용자와 음성 비서의 대화 내용을 저장하여 채팅창에 표시하는데 사용한다.\n",
        "- st.session_state['message'] : GPT API에 입력(input)으로 전달할 프롬프트 양식을 저장한다. 이전 질문과 답변 모두 차례로 누적하여 저장한다.\n",
        "- st.session_state['check_audio'] : 프로그램이 다시 실행될 때 마다 이전 녹음 파일의 정보가 버퍼에 남아서 실행되는 것을 방지하기 위해 사용자가 녹음한 음원을 리스트 형태로 저장한다. 새로운 녹음이 들어오면 저장해 둔 음원과 비교하여 새로운 녹음인지 판단한다."
      ],
      "metadata": {
        "id": "uaiAYBSF_3A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "# openai 패키지 추가\n",
        "import openai\n",
        "\n",
        "# 메인 함수\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "    page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        "  )\n",
        "\n",
        "############################\n",
        "## 2. 상태를 저장하기 위한 session_state 추가\n",
        "## 2-1  session state 초기화\n",
        "## 2-2 리셋 코드\n",
        "##################################\n",
        "  #2-1 session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\",\n",
        "                                     \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        " ###########################################\n",
        "\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "      '''\n",
        "      - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "      - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "      '''\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  ################################\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='API-Key 입력', placeholder='Enter Your API KEY', value='', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "##########################################\n",
        "# 2-2 리셋 코드\n",
        "########################################\n",
        "# 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat]과\n",
        "# st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "      st.session_state[\"chat\"] = []\n",
        "      st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea \"}]\n",
        "      st.session_state[\"check reset\"] = True\n",
        "###################################################################\n",
        "##########################\n",
        "# 기능 구현 공간(기능 구현 위하여)\n",
        "######################\n",
        "  col1, col2 = st.columns(2)\n",
        "  with col1:\n",
        "    #왼쪽 영역 생성\n",
        "    st.subheader('질문하기')\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 생성\n",
        "    st.subheader('질문/답변')\n",
        "###############################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuKdpbmdASwi",
        "outputId": "c4ceea42-8d4a-4250-b3ae-98e6fee7109a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFlj6rKOGO__",
        "outputId": "494bbcc9-9bf5-4474-9125-27035c482b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://7405-35-230-189-14.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.189.14:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "- 스트림릿의 기본 패키지에는 음성을 녹음하기 위한 기능이 없으므로 streamlit-audiorecorder라는  새로운 패키지를 설치한다.\n",
        "- streamlit-audiorecorder를 활용하면 스트림릿에서 음성 녹음 버튼을 생성하고, 녹음 결과를 파일로 저장할 수 있다."
      ],
      "metadata": {
        "id": "Vxda_C0QHvsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit-audiorecorder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM3DxQ4dHyVg",
        "outputId": "18bb3710-2316-465f-b9d0-7ffdbef3ddac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit-audiorecorder\n",
            "  Downloading streamlit_audiorecorder-0.0.4-py3-none-any.whl (447 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=0.63 in /usr/local/lib/python3.10/dist-packages (from streamlit-audiorecorder) (1.29.0)\n",
            "Collecting pydub>=0.24 (from streamlit-audiorecorder)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.11.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (5.2)\n",
            "Requirement already satisfied: validators<1,>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.22.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.1.40)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (6.3.2)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (4.0.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit>=0.63->streamlit-audiorecorder) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit>=0.63->streamlit-audiorecorder) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit>=0.63->streamlit-audiorecorder) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit>=0.63->streamlit-audiorecorder) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.63->streamlit-audiorecorder) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.63->streamlit-audiorecorder) (0.15.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.63->streamlit-audiorecorder) (0.1.2)\n",
            "Installing collected packages: pydub, streamlit-audiorecorder\n",
            "Successfully installed pydub-0.25.1 streamlit-audiorecorder-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiorecorder import audiorecorder\n",
        "print(dir(audiorecorder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GizfceF1ICbn",
        "outputId": "470f2cf5-f730-40dd-b127-4f4a47fa6377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " -  audiorecorder 패키지 추가\n",
        "\n",
        "from audiorecorder import audiorecorder\n",
        " -  파일 삭제를 위한 패키지 추가\n",
        "\n",
        " import os\n",
        " -  시간 정보를 위한 패키지 추가\n",
        "\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "raw08YF5I0ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "# openai 패키지 추가\n",
        "import openai\n",
        "\n",
        "# audiorecorder 패키지 추가\n",
        "from audiorecorder import audiorecorder\n",
        "# 파일 삭제를 위한 패키지 추가\n",
        "import os\n",
        "# 시간 정보를 위한 패키지 추가\n",
        "from datetime import datetime\n",
        "\n",
        "###기능 구현 함수#################\n",
        "def STT(audio):\n",
        "  # 파일 저장\n",
        "  filename='input.mp3'\n",
        "  audio.export(filename, format=\"mp3\")\n",
        "  # 음원 파일 열기\n",
        "  audio_file = open(filename, \"rb\")\n",
        "  # whisper 모델을 활용해 텍스트 얻기\n",
        "  transcript = openai.Audio.transcribe(\"whisper-1\", audio_file) # 모델 이름\n",
        "  audio_file.close()\n",
        "  # 파일 삭제\n",
        "  os.remove(filename)\n",
        "  return transcript[\"text\"]\n",
        "\n",
        "##### 메인 함수 ############\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "    page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        "  )\n",
        "\n",
        "############################\n",
        "## 2. 상태를 저장하기 위한 session_state 추가\n",
        "## 2-1  session state 초기화\n",
        "## 2-2 리셋 코드\n",
        "##################################\n",
        "  #2-1 session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\",\n",
        "                                     \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        " ###########################################\n",
        "\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "      '''\n",
        "      - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "      - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "      '''\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  ################################\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='API-Key 입력', placeholder='Enter Your API KEY', value='', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "    if st.button(label='초기화'):\n",
        "##########################################\n",
        "# 2-2 리셋 코드\n",
        "########################################\n",
        "# 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat]과\n",
        "# st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "      st.session_state[\"chat\"] = []\n",
        "      st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea \"}]\n",
        "      st.session_state[\"check reset\"] = True\n",
        "###################################################################\n",
        "##########################\n",
        "# 기능 구현 공간(기능 구현 위하여)\n",
        "######################\n",
        "  col1, col2 = st.columns(2)\n",
        "  with col1:\n",
        "    #왼쪽 영역 생성\n",
        "    st.subheader('질문하기')\n",
        "##########################\n",
        "# 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "# 3-1 사용자의 음성 입력받기 및 재생 버튼 생성하기\n",
        "###################################################\n",
        "# 음성 녹음 아이콘 추가\n",
        "# audiorecorder(start, stop, pause)\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\")\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      # 음성 재생\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "      # 음원 파일에서 텍스트 추출\n",
        "      question = STT(audio)\n",
        "\n",
        "      # 채팅을 시각화하기 위해 질문 내용 저장\n",
        "      now = datetime.now().strftime(\"%H:%M\")\n",
        "      st.session_state[\"chat\"] = st.session_state[\"chat\"]+[(\"user\", now, question)]\n",
        "      # GPT 모델에 넣을 프롬프트를 위해 질문 내용 저장\n",
        "      st.session_state[\"messages\"] = st.session_state[\"messages\"]+[{\"role\": \"user\", \"content\": question}]\n",
        "################################################\n",
        "\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 생성\n",
        "    st.subheader('질문/답변')\n",
        "###############################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shB1y1K5IxhQ",
        "outputId": "8df52478-b232-4418-d958-106ec5b65295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTdQ8CO3K_Ew",
        "outputId": "3357cfa1-7f90-4626-ba36-98f9b1c05924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://51b1-35-230-189-14.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.189.14:5000\u001b[0m\n",
            "\u001b[0m\n",
            "2023-12-28 03:12:22.151 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 534, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/drive/MyDrive/ai_chat_python/voicebot.py\", line 136, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/ai_chat_python/voicebot.py\", line 117, in main\n",
            "    question = STT(audio)\n",
            "  File \"/content/drive/MyDrive/ai_chat_python/voicebot.py\", line 17, in STT\n",
            "    audio.eport(filename, format=\"mp3\")\n",
            "AttributeError: 'AudioSegment' object has no attribute 'eport'\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Chat API로 질문하고 답변 구하기\n",
        "\n",
        " 5-1 ChatGPT API를 활용하여 답변 구하기\n",
        "\n",
        " 5-2 대화 내용을 채팅 형식으로 시각화하기\n",
        "\n",
        " [추가 library]\n",
        "  - TTS\n",
        "  \n",
        "  import gTTS"
      ],
      "metadata": {
        "id": "ZAYufUbAafCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUYq601_bqvz",
        "outputId": "5cd8b6df-51f6-42ce-feff-955e9f3d6035"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ai_chat_python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile voicebot.py\n",
        "#### 기본 정보 입력\n",
        "import streamlit as st\n",
        "# openai 패키지 추가\n",
        "import openai\n",
        "import base64\n",
        "\n",
        "# audiorecorder 패키지 추가\n",
        "from audiorecorder import audiorecorder\n",
        "# 파일 삭제를 위한 패키지 추가\n",
        "import os\n",
        "# 시간 정보를 위한 패키지 추가\n",
        "from datetime import datetime\n",
        "\n",
        "# TTS 패키지 추가\n",
        "from gtts import gTTS\n",
        "\n",
        "###기능 구현 함수#################\n",
        "def STT(audio):\n",
        "  # 파일 저장\n",
        "  filename='input.mp3'\n",
        "  audio.export(filename, format=\"mp3\")\n",
        "  # 음원 파일 열기\n",
        "  audio_file = open(filename, \"rb\")\n",
        "  # whisper 모델을 활용해 텍스트 얻기\n",
        "  transcript = openai.Audio.transcribe(\"whisper-1\", audio_file) # 모델 이름\n",
        "  audio_file.close()\n",
        "  # 파일 삭제\n",
        "  os.remove(filename)\n",
        "  return transcript[\"text\"]\n",
        "\n",
        "def ask_gpt(prompt, model):\n",
        "  response = openai.ChatCompletion.create(model=model, messages=prompt)\n",
        "  system_message = response[\"choices\"][0][\"message\"]\n",
        "  return system_message[\"content\"]\n",
        "\n",
        "def TTS(response):\n",
        "# gTTS 를 활용하여 음성 파일 생성\n",
        "  filename = \"output.mp3\"\n",
        "  tts = gTTS(text=response,lang=\"ko\")\n",
        "  tts.save(filename)\n",
        "\n",
        "  # 음원 파일 자동 재생\n",
        "  with open(filename, \"rb\") as f:\n",
        "    data = f.read()\n",
        "    b64 = base64.b64encode(data).decode()\n",
        "    md = f\"\"\"\n",
        "      <audio autoplay=\"True\">\n",
        "      <source src=\"data:audio/mp3;base64,{b64}\" type=\"audio/mp3\">\n",
        "      </audio>\n",
        "      \"\"\"\n",
        "    st.markdown(md,unsafe_allow_html=True,)\n",
        "   # 파일 삭제\n",
        "  os.remove(filename)\n",
        "\n",
        "##### 메인 함수 ############\n",
        "def main():\n",
        "\n",
        "  # 기본 설정\n",
        "  st.set_page_config(\n",
        "    page_title='음성 비서 프로그램',\n",
        "    layout='wide'\n",
        "  )\n",
        "\n",
        "############################\n",
        "## 2. 상태를 저장하기 위한 session_state 추가\n",
        "## 2-1  session state 초기화\n",
        "## 2-2 리셋 코드\n",
        "##################################\n",
        "  #2-1 session state 초기화\n",
        "  if \"chat\" not in st.session_state:\n",
        "    st.session_state[\"chat\"] = []\n",
        "\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\",\n",
        "                                     \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea\"}]\n",
        "\n",
        "  if \"check_reset\" not in st.session_state:\n",
        "    st.session_state[\"check_reset\"] = False\n",
        " ###########################################\n",
        "\n",
        "\n",
        "  # 제목\n",
        "  st.header('음성 비서 프로그램')\n",
        "\n",
        "  # 구분선\n",
        "  st.markdown('---------')\n",
        "\n",
        "  # 기본 설명\n",
        "  with st.expander('음성비서 프로그램에 관하여', expanded=True):\n",
        "    st.write(\n",
        "      '''\n",
        "      - 음성 비서 프로그램의 UI는 스트림릿을 활용했다.\n",
        "      - STT(speech-To-text)는 OpenAI의 OpenAI의 Whisper AI를 활용했다.\n",
        "      '''\n",
        "\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "  ################################\n",
        "  # 사이드바 설명\n",
        "  with st.sidebar:\n",
        "    # OPEN API API 키 입력받기\n",
        "    openai.api_key = st.text_input(label='API-Key 입력', placeholder='Enter Your API KEY', value='', type='password')\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "    # GPT 모델을 선택하기 위한 라디오 버튼 생성\n",
        "    model = st.radio(label='GPT 모델', options=['gpt-4', 'gpt-3.5-turbo'], index=1)\n",
        "\n",
        "    st.markdown('---')\n",
        "\n",
        "##########################################\n",
        "# 2-2 리셋 코드\n",
        "########################################\n",
        "# 리셋 버튼을 누르면 기존 대화 내용을 모두 삭제하기 위해 st.session_state['chat]과\n",
        "# st.session_state['message']의 session_state를 초기화 한다.\n",
        "\n",
        "\n",
        "    # 리셋 버튼 생성\n",
        "  if st.button(label='초기화'):\n",
        "    st.session_state[\"chat\"] = []\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"system\", \"content\": \"You are a thoughtful assistant. Respond to all input in 25 words and answer in korea \"}]\n",
        "    st.session_state[\"check_reset\"] = True\n",
        "###################################################################\n",
        "##########################\n",
        "# 기능 구현 공간(기능 구현 위하여)\n",
        "######################\n",
        "  col1, col2 = st.columns(2)\n",
        "  with col1:\n",
        "    #왼쪽 영역 생성\n",
        "    st.subheader('질문하기')\n",
        "##########################\n",
        "# 3. 스트림릿 오디오 레코더를 활용하여 음성 녹음하기\n",
        "# 3-1 사용자의 음성 입력받기 및 재생 버튼 생성하기\n",
        "###################################################\n",
        "# 음성 녹음 아이콘 추가\n",
        "# audiorecorder(start, stop, pause)\n",
        "    audio = audiorecorder(\"클릭하여 녹음하기\", \"녹음중...\")\n",
        "\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      # 음성 재생\n",
        "      st.audio(audio.export().read())\n",
        "\n",
        "      # 음원 파일에서 텍스트 추출\n",
        "      question = STT(audio)\n",
        "\n",
        "      # 채팅을 시각화하기 위해 질문 내용 저장\n",
        "      now = datetime.now().strftime(\"%H:%M\")\n",
        "      st.session_state[\"chat\"] = st.session_state[\"chat\"]+[(\"user\", now, question)]\n",
        "      # GPT 모델에 넣을 프롬프트를 위해 질문 내용 저장\n",
        "      st.session_state[\"messages\"] = st.session_state[\"messages\"]+[{\"role\": \"user\", \"content\": question}]\n",
        "################################################\n",
        "\n",
        "\n",
        "  with col2:\n",
        "    # 오른쪽 영역 생성\n",
        "    st.subheader('질문/답변')\n",
        "###############################\n",
        "   # 5. ChatGPT API로 질문하고 답변 구하기\n",
        "###############################\n",
        "    # 5.1 CHATGPT API를 활용하여 답변 구하기\n",
        "    ###################################\n",
        "    if (audio.duration_seconds > 0) and (st.session_state[\"check_reset\"]==False):\n",
        "      #ChatGPT에게 답변 얻기\n",
        "      response = ask_gpt(st.session_state[\"messages\"], model)\n",
        "\n",
        "      # GPT 모델에 넣을 프롬프트를 위해 답변 내용 저장\n",
        "      st.session_state[\"messages\"] = st.session_state[\"messages\"]+[{\"role\": \"user\", \"content\": question}]\n",
        "\n",
        "      # 채팅을 시각화하기 위해 질문 내용 저장\n",
        "      now = datetime.now().strftime(\"%H:%M\")\n",
        "      st.session_state[\"chat\"] = st.session_state[\"chat\"]+[(\"bot\", now, response)]\n",
        " #########################################################\n",
        "      ## 5-2 대화 내용을 채팅 형식으로 시각화 하기\n",
        "      #########################################################\n",
        "      # 채팅 형식으로 시각화 하기\n",
        "      for sender, time, message in st.session_state[\"chat\"]:\n",
        "          if sender == \"user\":\n",
        "              st.write(f'<div style=\"display:flex;align-items:center;\"><div style=\"background-color:#007AFF;color:white;border-radius:12px;padding:8px 12px;margin-right:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "              st.write(\"\")\n",
        "          else:\n",
        "              st.write(f'<div style=\"display:flex;align-items:center;justify-content:flex-end;\"><div style=\"background-color:lightgray;border-radius:12px;padding:8px 12px;margin-left:8px;\">{message}</div><div style=\"font-size:0.8rem;color:gray;\">{time}</div></div>', unsafe_allow_html=True)\n",
        "              st.write(\"\")\n",
        "\n",
        "      # gTTS 를 활용하여 음성 파일 생성 및 재생\n",
        "      TTS(response)\n",
        "    else:\n",
        "      st.session_state[\"check_reset\"] = False\n",
        "###################################################\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK8lxT7Ha4N1",
        "outputId": "b74e9982-39d4-4da7-f5d5-2128e059c3cf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting voicebot.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok은 외부(public)에서 로컬에 접속할 수 있게 도와주는 터널링 프로그램이다.\n",
        "# 서버역할 담당\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 5000\n",
        "ngrok.set_auth_token('2ZQFEyhRhNmYMVbeE1jegruZ0Ru_4rn2Xkke8VwvECCkGLm3G')\n",
        "print(dir(ngrok.connect(port)))\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print('click', public_url)\n",
        "\n",
        "# streamlit run /content/drive/MyDrive/chatgpt_api/voicebot.py ==server.port=5000\n",
        "!streamlit run voicebot2.py --server.port=5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTKImb1QbqwD",
        "outputId": "ff9e7e20-4965-42d0-d809-b4e382176963"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'api_url', 'config', 'data', 'id', 'metrics', 'name', 'proto', 'public_url', 'pyngrok_config', 'refresh_metrics', 'uri']\n",
            "click https://9845-35-230-189-14.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:5000\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.189.14:5000\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. 배포\n",
        " - 깃허브 레포지토리(저장소) 생성하기 - voicebot\n",
        " -"
      ],
      "metadata": {
        "id": "mZOQ9-qcUe3b"
      }
    }
  ]
}